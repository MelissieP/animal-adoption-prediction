{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_data():\n",
    "    train = pd.read_csv(\"input/train.csv\")\n",
    "    test = pd.read_csv(\"input/test.csv\")\n",
    "    breeds = pd.read_csv(\"input/breed_labels.csv\")\n",
    "    colours = pd.read_csv(\"input/color_labels.csv\")\n",
    "    return train, test, breeds, colours\n",
    "\n",
    "def standardise_unnamed_pets(train, test):\n",
    "    train[\"Name\"] = train[\"Name\"].fillna(\"Unnamed\")\n",
    "    train[\"Name\"] = np.where(train[\"Name\"] == \"No Name\", \"Unnamed\", train[\"Name\"])\n",
    "    train[\"Name\"] = np.where(train[\"Name\"] == \"None\", \"Unnamed\", train[\"Name\"])\n",
    "    train[\"Name\"] = np.where(train[\"Name\"] == \"No Name Yet\", \"Unnamed\", train[\"Name\"])\n",
    "\n",
    "    test[\"Name\"] = test[\"Name\"].fillna(\"Unnamed\")\n",
    "    test[\"Name\"] = np.where(test[\"Name\"] == \"No Name\", \"Unnamed\", test[\"Name\"])\n",
    "    test[\"Name\"] = np.where(test[\"Name\"] == \"None\", \"Unnamed\", test[\"Name\"])\n",
    "    test[\"Name\"] = np.where(test[\"Name\"] == \"No Name Yet\", \"Unnamed\", test[\"Name\"])\n",
    "    return train, test\n",
    "\n",
    "def create_unnamed_feature(train, test):\n",
    "    train[\"Unnamed\"] = 0\n",
    "    train.loc[train[\"Name\"] == \"Unnamed\", \"Unnamed\"] = 1\n",
    "\n",
    "    test[\"Unnamed\"] = 0\n",
    "    test.loc[test[\"Name\"] == \"Unnamed\", \"Unnamed\"] = 1\n",
    "    return train, test\n",
    "\n",
    "def drop_na_values(train, test):\n",
    "    train = train.fillna(0)\n",
    "    test = test.fillna(0)\n",
    "    return train, test\n",
    "\n",
    "def create_mixed_breed_feature(train, test):\n",
    "    train[\"MixedBreed\"] = [1 if x > 0 else 0 for x in train[\"Breed2\"]]\n",
    "    test[\"MixedBreed\"] = [1 if x > 0 else 0 for x in test[\"Breed2\"]]\n",
    "    return train, test\n",
    "\n",
    "def breed_df_to_dict(breeds):\n",
    "    breed_cols = breeds[[\"BreedID\", \"BreedName\"]]\n",
    "    breed_cols.set_index(\"BreedID\", drop=True, inplace=True)\n",
    "    breed_dict = breed_cols.to_dict()[\"BreedName\"]\n",
    "    return breed_dict\n",
    "\n",
    "def map_dictionary_to_breed_names(breed_dict, train, test):\n",
    "    train[\"BreedName_1\"] = train[\"Breed1\"].map(breed_dict).fillna(\"Unknown\")\n",
    "    train[\"BreedName_2\"] = train[\"Breed2\"].map(breed_dict).fillna(\"None\")\n",
    "\n",
    "    test[\"BreedName_1\"] = test[\"Breed1\"].map(breed_dict).fillna(\"Unknown\")\n",
    "    test[\"BreedName_2\"] = test[\"Breed2\"].map(breed_dict).fillna(\"None\")\n",
    "\n",
    "    # Make all the cases pure bred if breed 1 is the same as breed 2\n",
    "    train.loc[train[\"BreedName_1\"] == train[\"BreedName_2\"], \"MixedBreed\"] = 0\n",
    "    test.loc[test[\"BreedName_1\"] == test[\"BreedName_2\"], \"MixedBreed\"] = 0\n",
    "\n",
    "    # But for the following cases, they are mixed:\n",
    "    train.loc[train[\"BreedName_1\"] == \"Mixed Breed\", \"MixedBreed\"] = 1\n",
    "    train.loc[train[\"BreedName_1\"] == \"Domestic Short Hair\", \"MixedBreed\"] = 1\n",
    "    train.loc[train[\"BreedName_1\"] == \"Domestic Medium Hair\", \"MixedBreed\"] = 1\n",
    "    train.loc[train[\"BreedName_1\"] == \"Domestic Long Hair\", \"MixedBreed\"] = 1\n",
    "\n",
    "    test.loc[test[\"BreedName_1\"] == \"Mixed Breed\", \"MixedBreed\"] = 1\n",
    "    test.loc[test[\"BreedName_1\"] == \"Domestic Short Hair\", \"MixedBreed\"] = 1\n",
    "    test.loc[test[\"BreedName_1\"] == \"Domestic Medium Hair\", \"MixedBreed\"] = 1\n",
    "    test.loc[test[\"BreedName_1\"] == \"Domestic Long Hair\", \"MixedBreed\"] = 1\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def create_description_length_feature(train, test):\n",
    "    train[\"Description\"] = train[\"Description\"].fillna(\"\")\n",
    "    train[\"Description_Character_Count\"] = train[\"Description\"].apply(lambda x: len(x))\n",
    "    train[\"Description_Word_Count\"] = train[\"Description\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "    test[\"Description\"] = test[\"Description\"].fillna(\"\")\n",
    "    test[\"Description_Character_Count\"] = test[\"Description\"].apply(lambda x: len(x))\n",
    "    test[\"Description_Word_Count\"] = test[\"Description\"].apply(lambda x: len(x.split()))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, breeds, colours = read_in_data()\n",
    "train, test = standardise_unnamed_pets(train, test)\n",
    "train, test = create_unnamed_feature(train, test)\n",
    "train, test = create_mixed_breed_feature(train, test)\n",
    "breed_dict = breed_df_to_dict(breeds)\n",
    "train, test = map_dictionary_to_breed_names(breed_dict, train, test)\n",
    "train, test = create_description_length_feature(train, test)\n",
    "\n",
    "train, test = drop_na_values(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_character_quantile_columns(df):\n",
    "    character_25 = df[\"Description_Character_Count\"].quantile(q=0.25)\n",
    "    character_5 = df[\"Description_Character_Count\"].quantile(q=0.5)\n",
    "    character_75 = df[\"Description_Character_Count\"].quantile(q=0.75)\n",
    "\n",
    "    df[\"Character_25\"] = 0\n",
    "    df.loc[df[\"Description_Character_Count\"] <= character_25, \"Character_25\"] = 1\n",
    "\n",
    "    df[\"Character_5\"] = 0\n",
    "    df.loc[(df[\"Description_Character_Count\"] > character_25) & (\n",
    "            df[\"Description_Character_Count\"] <= character_5), \"Character_5\"] = 1\n",
    "\n",
    "    df[\"Character_75\"] = 0\n",
    "    df.loc[(df[\"Description_Character_Count\"] > character_5) & (\n",
    "            df[\"Description_Character_Count\"] <= character_75), \"Character_75\"] = 1\n",
    "\n",
    "    df[\"Character_100\"] = 0\n",
    "    df.loc[(df[\"Description_Character_Count\"] > character_75), \"Character_100\"] = 1\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_word_quantile_columns(df):\n",
    "    word_25 = df[\"Description_Word_Count\"].quantile(q=0.25)\n",
    "    word_5 = df[\"Description_Word_Count\"].quantile(q=0.5)\n",
    "    word_75 = df[\"Description_Word_Count\"].quantile(q=0.75)\n",
    "\n",
    "    df[\"Word_25\"] = 0\n",
    "    df.loc[df[\"Description_Word_Count\"] <= word_25, \"Word_25\"] = 1\n",
    "\n",
    "    df[\"Word_5\"] = 0\n",
    "    df.loc[(df[\"Description_Word_Count\"] > word_25) & (\n",
    "            df[\"Description_Word_Count\"] <= word_5), \"Word_5\"] = 1\n",
    "\n",
    "    df[\"Word_75\"] = 0\n",
    "    df.loc[(df[\"Description_Word_Count\"] > word_5) & (\n",
    "            df[\"Description_Word_Count\"] <= word_75), \"Word_75\"] = 1\n",
    "\n",
    "    df[\"Word_100\"] = 0\n",
    "    df.loc[(df[\"Description_Word_Count\"] > word_75), \"Word_100\"] = 1\n",
    "    return df\n",
    "\n",
    "def bucket_ages(df):\n",
    "    # Drop Ages thats = 0\n",
    "    df = df[df[\"Age\"] > 0]\n",
    "    df[\"Puppy\"] = 0\n",
    "    df[\"Adult\"] = 0\n",
    "    df[\"Senior\"] = 0\n",
    "    df.loc[(df[\"Age\"] >= 1) & (df[\"Age\"] < 12), \"Puppy\"] = 1\n",
    "    df.loc[(df[\"Age\"] >= 12) & (df[\"Age\"] < 96), \"Adult\"] = 1\n",
    "    df.loc[(df[\"Age\"] >= 96, \"Senior\")] = 1\n",
    "    return df\n",
    "\n",
    "def bucket_fees(df):\n",
    "    fee_25 = df[\"Fee\"].quantile(q=0.25)\n",
    "    fee_5 = df[\"Fee\"].quantile(q=0.5)\n",
    "    fee_75 = df[\"Fee\"].quantile(q=0.75)\n",
    "    df[\"No_Fee\"] = 0\n",
    "    df[\"Fee_25\"] = 0\n",
    "    df[\"Fee_5\"] = 0\n",
    "    df[\"Fee_75\"] = 0\n",
    "    df[\"Fee_100\"] = 0\n",
    "    df.loc[df[\"Fee\"] == 0, \"No_Fee\"] = 1\n",
    "    df.loc[(df[\"Fee\"] > 0) & (\n",
    "            df[\"Fee\"] <= fee_25), \"Fee_25\"] = 1\n",
    "    df.loc[(df[\"Fee\"] > fee_25) & (\n",
    "            df[\"Fee\"] <= fee_5), \"Fee_5\"] = 1\n",
    "    df.loc[(df[\"Fee\"] > fee_5) & (\n",
    "            df[\"Fee\"] <= fee_75), \"Fee_75\"] = 1\n",
    "    df.loc[(df[\"Fee\"] > fee_75), \"Fee_100\"] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = create_character_quantile_columns(train)\n",
    "test = create_character_quantile_columns(test)\n",
    "train = create_word_quantile_columns(train)\n",
    "test = create_word_quantile_columns(test)\n",
    "train = bucket_ages(train)\n",
    "test = bucket_ages(test)\n",
    "train = bucket_fees(train)\n",
    "test = bucket_fees(test)\n",
    "\n",
    "Y_train = train[\"AdoptionSpeed\"]\n",
    "\n",
    "train = train.drop(\n",
    "    columns=[\"AdoptionSpeed\", \"PetID\", \"Name\", \"State\", \"RescuerID\", \"Description\", \"BreedName_1\", \"BreedName_2\",\n",
    "            \"Fee\", \"Description_Character_Count\", \"Description_Word_Count\", \"Age\"])\n",
    "\n",
    "test = test.drop(\n",
    "    columns=[\"PetID\", \"Name\", \"State\", \"RescuerID\", \"Description\", \"BreedName_1\", \"BreedName_2\",\n",
    "            \"Fee\", \"Description_Character_Count\", \"Description_Word_Count\", \"Age\"])\n",
    "\n",
    "data = train.append(test)\n",
    "data = pd.get_dummies(data, columns = [\"Type\", \"Gender\", \"MaturitySize\", \"FurLength\", \n",
    "                                         \"Vaccinated\", \"Dewormed\", \"Sterilized\", \n",
    "                                         \"Health\", 'Breed1', 'Breed2', 'Color1', 'Color2', 'Color3', 'Quantity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.iloc[:14814, :]\n",
    "X_test = data.iloc[:14814, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Separate target variable from training set, and remove unnecessary columns\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_train)\n",
    "y_train = encoder.transform(Y_train)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 400\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(420,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(300))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(20))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9880 samples, validate on 4934 samples\n",
      "Epoch 1/400\n",
      "9880/9880 [==============================] - ETA: 0s - loss: 1.4600 - acc: 0.302 - 2s 156us/step - loss: 1.4585 - acc: 0.3033 - val_loss: 1.4120 - val_acc: 0.3308\n",
      "Epoch 2/400\n",
      "9880/9880 [==============================] - 1s 98us/step - loss: 1.4154 - acc: 0.3461 - val_loss: 1.4061 - val_acc: 0.3626\n",
      "Epoch 3/400\n",
      "9880/9880 [==============================] - 1s 99us/step - loss: 1.3863 - acc: 0.3778 - val_loss: 1.3926 - val_acc: 0.3620\n",
      "Epoch 4/400\n",
      "9880/9880 [==============================] - 1s 101us/step - loss: 1.3645 - acc: 0.3851 - val_loss: 1.3911 - val_acc: 0.3766\n",
      "Epoch 5/400\n",
      "9880/9880 [==============================] - 1s 98us/step - loss: 1.3430 - acc: 0.4053 - val_loss: 1.3738 - val_acc: 0.3861\n",
      "Epoch 6/400\n",
      "9880/9880 [==============================] - 1s 100us/step - loss: 1.3215 - acc: 0.4182 - val_loss: 1.4042 - val_acc: 0.3593\n",
      "Epoch 7/400\n",
      "9880/9880 [==============================] - 1s 97us/step - loss: 1.2991 - acc: 0.4316 - val_loss: 1.3817 - val_acc: 0.3778\n",
      "Epoch 8/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 1.2674 - acc: 0.4459 - val_loss: 1.4125 - val_acc: 0.3747\n",
      "Epoch 9/400\n",
      "9880/9880 [==============================] - 1s 97us/step - loss: 1.2309 - acc: 0.4680 - val_loss: 1.4881 - val_acc: 0.3478\n",
      "Epoch 10/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 1.1983 - acc: 0.4852 - val_loss: 1.4611 - val_acc: 0.3516\n",
      "Epoch 11/400\n",
      "9880/9880 [==============================] - 1s 98us/step - loss: 1.1525 - acc: 0.5127 - val_loss: 1.5030 - val_acc: 0.3565\n",
      "Epoch 12/400\n",
      "9880/9880 [==============================] - 1s 100us/step - loss: 1.1235 - acc: 0.5256 - val_loss: 1.4706 - val_acc: 0.3656\n",
      "Epoch 13/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 1.0671 - acc: 0.5624 - val_loss: 1.5654 - val_acc: 0.3711\n",
      "Epoch 14/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 1.0258 - acc: 0.5750 - val_loss: 1.6409 - val_acc: 0.3561\n",
      "Epoch 15/400\n",
      "9880/9880 [==============================] - 1s 98us/step - loss: 0.9783 - acc: 0.5933 - val_loss: 1.7866 - val_acc: 0.3595\n",
      "Epoch 16/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.9406 - acc: 0.6155 - val_loss: 1.6727 - val_acc: 0.3539\n",
      "Epoch 17/400\n",
      "9880/9880 [==============================] - 1s 98us/step - loss: 0.8867 - acc: 0.6384 - val_loss: 2.1277 - val_acc: 0.2927\n",
      "Epoch 18/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.8436 - acc: 0.6553 - val_loss: 1.8752 - val_acc: 0.3535\n",
      "Epoch 19/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.8160 - acc: 0.6662 - val_loss: 1.9618 - val_acc: 0.3229\n",
      "Epoch 20/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.7585 - acc: 0.6928 - val_loss: 2.1165 - val_acc: 0.3210\n",
      "Epoch 21/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.7165 - acc: 0.7151 - val_loss: 2.0269 - val_acc: 0.3366\n",
      "Epoch 22/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.7007 - acc: 0.7253 - val_loss: 2.2827 - val_acc: 0.3531\n",
      "Epoch 23/400\n",
      "9880/9880 [==============================] - 1s 98us/step - loss: 0.6439 - acc: 0.7405 - val_loss: 2.3447 - val_acc: 0.3247\n",
      "Epoch 24/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.6007 - acc: 0.7675 - val_loss: 2.1722 - val_acc: 0.3415\n",
      "Epoch 25/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.5565 - acc: 0.7900 - val_loss: 2.6341 - val_acc: 0.3393\n",
      "Epoch 26/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.5370 - acc: 0.7965 - val_loss: 2.7086 - val_acc: 0.3342\n",
      "Epoch 27/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.4718 - acc: 0.8188 - val_loss: 2.8744 - val_acc: 0.3504\n",
      "Epoch 28/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.4744 - acc: 0.8146 - val_loss: 2.7277 - val_acc: 0.3397\n",
      "Epoch 29/400\n",
      "9880/9880 [==============================] - 1s 97us/step - loss: 0.4402 - acc: 0.8331 - val_loss: 2.8106 - val_acc: 0.3421\n",
      "Epoch 30/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.4015 - acc: 0.8526 - val_loss: 2.9445 - val_acc: 0.3510\n",
      "Epoch 31/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.3750 - acc: 0.8613 - val_loss: 3.2992 - val_acc: 0.3476\n",
      "Epoch 32/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.3544 - acc: 0.8686 - val_loss: 3.3346 - val_acc: 0.3227\n",
      "Epoch 33/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.3550 - acc: 0.8757 - val_loss: 3.4964 - val_acc: 0.3354\n",
      "Epoch 34/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.3302 - acc: 0.8813 - val_loss: 3.4600 - val_acc: 0.3506\n",
      "Epoch 35/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.3540 - acc: 0.8817 - val_loss: 3.4608 - val_acc: 0.3439\n",
      "Epoch 36/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.2757 - acc: 0.9005 - val_loss: 3.8734 - val_acc: 0.3437\n",
      "Epoch 37/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.2881 - acc: 0.8957 - val_loss: 3.5057 - val_acc: 0.3298\n",
      "Epoch 38/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.2693 - acc: 0.9021 - val_loss: 3.7162 - val_acc: 0.3360\n",
      "Epoch 39/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.2637 - acc: 0.9056 - val_loss: 3.8934 - val_acc: 0.3397\n",
      "Epoch 40/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.2506 - acc: 0.9087 - val_loss: 3.7293 - val_acc: 0.3452\n",
      "Epoch 41/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.2329 - acc: 0.9195 - val_loss: 4.3080 - val_acc: 0.3038\n",
      "Epoch 42/400\n",
      "9880/9880 [==============================] - 1s 98us/step - loss: 0.2089 - acc: 0.9248 - val_loss: 4.1036 - val_acc: 0.3263\n",
      "Epoch 43/400\n",
      "9880/9880 [==============================] - 1s 99us/step - loss: 0.2021 - acc: 0.9256 - val_loss: 4.5081 - val_acc: 0.3320\n",
      "Epoch 44/400\n",
      "9880/9880 [==============================] - 1s 99us/step - loss: 0.2146 - acc: 0.9254 - val_loss: 4.3593 - val_acc: 0.3423\n",
      "Epoch 45/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.2188 - acc: 0.9291 - val_loss: 4.0970 - val_acc: 0.3287\n",
      "Epoch 46/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.1924 - acc: 0.9339 - val_loss: 4.5859 - val_acc: 0.3537\n",
      "Epoch 47/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.2326 - acc: 0.9236 - val_loss: 3.8638 - val_acc: 0.3046\n",
      "Epoch 48/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.1980 - acc: 0.9288 - val_loss: 3.9814 - val_acc: 0.3150\n",
      "Epoch 49/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.1642 - acc: 0.9425 - val_loss: 4.3083 - val_acc: 0.3336\n",
      "Epoch 50/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.1606 - acc: 0.9415 - val_loss: 4.6587 - val_acc: 0.3253\n",
      "Epoch 51/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.1874 - acc: 0.9332 - val_loss: 4.5296 - val_acc: 0.3462\n",
      "Epoch 52/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.1713 - acc: 0.9395 - val_loss: 4.5988 - val_acc: 0.3395\n",
      "Epoch 53/400\n",
      "9880/9880 [==============================] - 1s 98us/step - loss: 0.1570 - acc: 0.9444 - val_loss: 4.5910 - val_acc: 0.3334\n",
      "Epoch 54/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.1674 - acc: 0.9391 - val_loss: 4.5206 - val_acc: 0.3358\n",
      "Epoch 55/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.1446 - acc: 0.9472 - val_loss: 4.7205 - val_acc: 0.3452\n",
      "Epoch 56/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.1558 - acc: 0.9451 - val_loss: 4.7509 - val_acc: 0.3259\n",
      "Epoch 57/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.1654 - acc: 0.9409 - val_loss: 4.2210 - val_acc: 0.3437\n",
      "Epoch 58/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.1508 - acc: 0.9451 - val_loss: 4.8240 - val_acc: 0.3450\n",
      "Epoch 59/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.1284 - acc: 0.9514 - val_loss: 4.8347 - val_acc: 0.3474\n",
      "Epoch 60/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.1721 - acc: 0.9396 - val_loss: 4.3985 - val_acc: 0.3362\n",
      "Epoch 61/400\n",
      "9880/9880 [==============================] - 1s 89us/step - loss: 0.1382 - acc: 0.9488 - val_loss: 4.3716 - val_acc: 0.3328\n",
      "Epoch 62/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.1154 - acc: 0.9551 - val_loss: 4.9855 - val_acc: 0.3362\n",
      "Epoch 63/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.1553 - acc: 0.9463 - val_loss: 5.1007 - val_acc: 0.3356\n",
      "Epoch 64/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.1378 - acc: 0.9493 - val_loss: 4.5536 - val_acc: 0.3470\n",
      "Epoch 65/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.1187 - acc: 0.9538 - val_loss: 5.0247 - val_acc: 0.3456\n",
      "Epoch 66/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.1167 - acc: 0.9530 - val_loss: 4.8526 - val_acc: 0.3300\n",
      "Epoch 67/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.1350 - acc: 0.9522 - val_loss: 5.2349 - val_acc: 0.3411\n",
      "Epoch 68/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.1159 - acc: 0.9553 - val_loss: 5.2860 - val_acc: 0.3423\n",
      "Epoch 69/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.1648 - acc: 0.9477 - val_loss: 5.1485 - val_acc: 0.3415\n",
      "Epoch 70/400\n",
      "9880/9880 [==============================] - 1s 90us/step - loss: 0.1369 - acc: 0.9505 - val_loss: 5.0977 - val_acc: 0.3342\n",
      "Epoch 71/400\n",
      "9880/9880 [==============================] - 1s 90us/step - loss: 0.0914 - acc: 0.9605 - val_loss: 5.5172 - val_acc: 0.3435\n",
      "Epoch 72/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.1046 - acc: 0.9552 - val_loss: 5.2236 - val_acc: 0.3500\n",
      "Epoch 73/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.1301 - acc: 0.9524 - val_loss: 5.3870 - val_acc: 0.3425\n",
      "Epoch 74/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.0898 - acc: 0.9631 - val_loss: 5.8493 - val_acc: 0.3375\n",
      "Epoch 75/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.1058 - acc: 0.9590 - val_loss: 5.8238 - val_acc: 0.3389\n",
      "Epoch 76/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.1224 - acc: 0.9533 - val_loss: 5.4558 - val_acc: 0.3429\n",
      "Epoch 77/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.1259 - acc: 0.9537 - val_loss: 5.2498 - val_acc: 0.3407\n",
      "Epoch 78/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.0908 - acc: 0.9614 - val_loss: 5.4768 - val_acc: 0.3439\n",
      "Epoch 79/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.1228 - acc: 0.9539 - val_loss: 5.1484 - val_acc: 0.3413\n",
      "Epoch 80/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.0891 - acc: 0.9638 - val_loss: 5.7365 - val_acc: 0.3373\n",
      "Epoch 81/400\n",
      "9880/9880 [==============================] - 1s 89us/step - loss: 0.0910 - acc: 0.9608 - val_loss: 5.9942 - val_acc: 0.3350\n",
      "Epoch 82/400\n",
      "9880/9880 [==============================] - 1s 90us/step - loss: 0.1376 - acc: 0.9524 - val_loss: 5.7614 - val_acc: 0.3318\n",
      "Epoch 83/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0809 - acc: 0.9651 - val_loss: 5.8373 - val_acc: 0.3340\n",
      "Epoch 84/400\n",
      "9880/9880 [==============================] - 1s 101us/step - loss: 0.1289 - acc: 0.9536 - val_loss: 5.9439 - val_acc: 0.3393\n",
      "Epoch 85/400\n",
      "9880/9880 [==============================] - 1s 132us/step - loss: 0.1128 - acc: 0.9563 - val_loss: 5.9436 - val_acc: 0.3409\n",
      "Epoch 86/400\n",
      "9880/9880 [==============================] - 1s 116us/step - loss: 0.1032 - acc: 0.9585 - val_loss: 5.4192 - val_acc: 0.3354\n",
      "Epoch 87/400\n",
      "9880/9880 [==============================] - 1s 98us/step - loss: 0.1002 - acc: 0.9585 - val_loss: 5.7415 - val_acc: 0.3385\n",
      "Epoch 88/400\n",
      "9880/9880 [==============================] - 1s 103us/step - loss: 0.1087 - acc: 0.9594 - val_loss: 5.6034 - val_acc: 0.3391\n",
      "Epoch 89/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.0708 - acc: 0.9672 - val_loss: 6.0714 - val_acc: 0.3439\n",
      "Epoch 90/400\n",
      "9880/9880 [==============================] - 1s 90us/step - loss: 0.1245 - acc: 0.9540 - val_loss: 5.1055 - val_acc: 0.3397\n",
      "Epoch 91/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0674 - acc: 0.9688 - val_loss: 5.9964 - val_acc: 0.3514\n",
      "Epoch 92/400\n",
      "9880/9880 [==============================] - 1s 90us/step - loss: 0.1070 - acc: 0.9576 - val_loss: 5.8866 - val_acc: 0.3411\n",
      "Epoch 93/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.1236 - acc: 0.9554 - val_loss: 5.6468 - val_acc: 0.3391\n",
      "Epoch 94/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.0625 - acc: 0.9711 - val_loss: 6.0766 - val_acc: 0.3401\n",
      "Epoch 95/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.0963 - acc: 0.9593 - val_loss: 5.9101 - val_acc: 0.3332\n",
      "Epoch 96/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.0724 - acc: 0.9682 - val_loss: 5.9839 - val_acc: 0.3482\n",
      "Epoch 97/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.0831 - acc: 0.9633 - val_loss: 6.4316 - val_acc: 0.3356\n",
      "Epoch 98/400\n",
      "9880/9880 [==============================] - 1s 90us/step - loss: 0.0943 - acc: 0.9612 - val_loss: 6.3136 - val_acc: 0.3500\n",
      "Epoch 99/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.0772 - acc: 0.9652 - val_loss: 6.2860 - val_acc: 0.3462\n",
      "Epoch 100/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0879 - acc: 0.9620 - val_loss: 6.3006 - val_acc: 0.3431\n",
      "Epoch 101/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.0859 - acc: 0.9631 - val_loss: 6.2953 - val_acc: 0.3458\n",
      "Epoch 102/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.0958 - acc: 0.9612 - val_loss: 5.7972 - val_acc: 0.3281\n",
      "Epoch 103/400\n",
      "9880/9880 [==============================] - 1s 103us/step - loss: 0.0666 - acc: 0.9695 - val_loss: 6.4566 - val_acc: 0.3328\n",
      "Epoch 104/400\n",
      "9880/9880 [==============================] - 1s 108us/step - loss: 0.0900 - acc: 0.9652 - val_loss: 6.0793 - val_acc: 0.3439\n",
      "Epoch 105/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0684 - acc: 0.9688 - val_loss: 6.5302 - val_acc: 0.3452\n",
      "Epoch 106/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.0865 - acc: 0.9646 - val_loss: 6.1869 - val_acc: 0.3427\n",
      "Epoch 107/400\n",
      "9880/9880 [==============================] - 1s 101us/step - loss: 0.0769 - acc: 0.9658 - val_loss: 6.2429 - val_acc: 0.3310\n",
      "Epoch 108/400\n",
      "9880/9880 [==============================] - 1s 98us/step - loss: 0.0717 - acc: 0.9669 - val_loss: 6.3726 - val_acc: 0.3379\n",
      "Epoch 109/400\n",
      "9880/9880 [==============================] - 1s 101us/step - loss: 0.0690 - acc: 0.9692 - val_loss: 6.5769 - val_acc: 0.3443\n",
      "Epoch 110/400\n",
      "9880/9880 [==============================] - 1s 103us/step - loss: 0.0823 - acc: 0.9644 - val_loss: 6.3944 - val_acc: 0.3350\n",
      "Epoch 111/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.1089 - acc: 0.9614 - val_loss: 6.1655 - val_acc: 0.3407\n",
      "Epoch 112/400\n",
      "9880/9880 [==============================] - 1s 90us/step - loss: 0.0576 - acc: 0.9729 - val_loss: 6.6031 - val_acc: 0.3379\n",
      "Epoch 113/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0852 - acc: 0.9641 - val_loss: 6.6379 - val_acc: 0.3342\n",
      "Epoch 114/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0587 - acc: 0.9698 - val_loss: 6.7037 - val_acc: 0.3458\n",
      "Epoch 115/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0942 - acc: 0.9610 - val_loss: 6.4360 - val_acc: 0.3385\n",
      "Epoch 116/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0580 - acc: 0.9703 - val_loss: 6.7445 - val_acc: 0.3348\n",
      "Epoch 117/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0763 - acc: 0.9668 - val_loss: 6.7650 - val_acc: 0.3352\n",
      "Epoch 118/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0746 - acc: 0.9663 - val_loss: 6.5717 - val_acc: 0.3362\n",
      "Epoch 119/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0865 - acc: 0.9632 - val_loss: 6.2077 - val_acc: 0.3409\n",
      "Epoch 120/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.0628 - acc: 0.9700 - val_loss: 6.5918 - val_acc: 0.3245\n",
      "Epoch 121/400\n",
      "9880/9880 [==============================] - 1s 88us/step - loss: 0.0682 - acc: 0.9700 - val_loss: 6.8099 - val_acc: 0.3324\n",
      "Epoch 122/400\n",
      "9880/9880 [==============================] - 1s 90us/step - loss: 0.0657 - acc: 0.9699 - val_loss: 6.8592 - val_acc: 0.3452\n",
      "Epoch 123/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.0783 - acc: 0.9652 - val_loss: 6.5182 - val_acc: 0.3383\n",
      "Epoch 124/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0874 - acc: 0.9636 - val_loss: 6.4030 - val_acc: 0.3383\n",
      "Epoch 125/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0608 - acc: 0.9688 - val_loss: 6.3285 - val_acc: 0.3316\n",
      "Epoch 126/400\n",
      "9880/9880 [==============================] - 1s 101us/step - loss: 0.0678 - acc: 0.9697 - val_loss: 6.7650 - val_acc: 0.3366\n",
      "Epoch 127/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0600 - acc: 0.9705 - val_loss: 6.9615 - val_acc: 0.3419\n",
      "Epoch 128/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0695 - acc: 0.9684 - val_loss: 6.8310 - val_acc: 0.3328\n",
      "Epoch 129/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0733 - acc: 0.9669 - val_loss: 6.7665 - val_acc: 0.3389\n",
      "Epoch 130/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0698 - acc: 0.9685 - val_loss: 6.2742 - val_acc: 0.3421\n",
      "Epoch 131/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0629 - acc: 0.9712 - val_loss: 6.5957 - val_acc: 0.3334\n",
      "Epoch 132/400\n",
      "9880/9880 [==============================] - 1s 89us/step - loss: 0.0884 - acc: 0.9619 - val_loss: 6.1291 - val_acc: 0.3415\n",
      "Epoch 133/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0486 - acc: 0.9754 - val_loss: 7.2669 - val_acc: 0.3304\n",
      "Epoch 134/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0612 - acc: 0.9713 - val_loss: 7.0447 - val_acc: 0.3474\n",
      "Epoch 135/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.0649 - acc: 0.9678 - val_loss: 7.1008 - val_acc: 0.3415\n",
      "Epoch 136/400\n",
      "9880/9880 [==============================] - 1s 90us/step - loss: 0.0762 - acc: 0.9661 - val_loss: 6.7977 - val_acc: 0.3312\n",
      "Epoch 137/400\n",
      "9880/9880 [==============================] - 1s 89us/step - loss: 0.0876 - acc: 0.9651 - val_loss: 6.7094 - val_acc: 0.3385\n",
      "Epoch 138/400\n",
      "9880/9880 [==============================] - 1s 88us/step - loss: 0.0499 - acc: 0.9731 - val_loss: 6.9891 - val_acc: 0.3308\n",
      "Epoch 139/400\n",
      "9880/9880 [==============================] - 1s 89us/step - loss: 0.0925 - acc: 0.9630 - val_loss: 6.3154 - val_acc: 0.3464\n",
      "Epoch 140/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0540 - acc: 0.9735 - val_loss: 6.9186 - val_acc: 0.3342\n",
      "Epoch 141/400\n",
      "9880/9880 [==============================] - 1s 89us/step - loss: 0.1243 - acc: 0.9598 - val_loss: 6.1996 - val_acc: 0.3460\n",
      "Epoch 142/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.0491 - acc: 0.9748 - val_loss: 6.7507 - val_acc: 0.3405\n",
      "Epoch 143/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0654 - acc: 0.9704 - val_loss: 6.7985 - val_acc: 0.3342\n",
      "Epoch 144/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0617 - acc: 0.9714 - val_loss: 7.0362 - val_acc: 0.3373\n",
      "Epoch 145/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0986 - acc: 0.9618 - val_loss: 6.4371 - val_acc: 0.3360\n",
      "Epoch 146/400\n",
      "9880/9880 [==============================] - 1s 87us/step - loss: 0.0451 - acc: 0.9755 - val_loss: 7.1630 - val_acc: 0.3504\n",
      "Epoch 147/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0654 - acc: 0.9675 - val_loss: 6.9456 - val_acc: 0.3393\n",
      "Epoch 148/400\n",
      "9880/9880 [==============================] - 1s 88us/step - loss: 0.0575 - acc: 0.9703 - val_loss: 6.7691 - val_acc: 0.3403\n",
      "Epoch 149/400\n",
      "9880/9880 [==============================] - 1s 88us/step - loss: 0.0805 - acc: 0.9667 - val_loss: 6.9143 - val_acc: 0.3462\n",
      "Epoch 150/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0512 - acc: 0.9735 - val_loss: 7.0013 - val_acc: 0.3448\n",
      "Epoch 151/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0613 - acc: 0.9715 - val_loss: 7.0545 - val_acc: 0.3423\n",
      "Epoch 152/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0652 - acc: 0.9695 - val_loss: 6.8473 - val_acc: 0.3383\n",
      "Epoch 153/400\n",
      "9880/9880 [==============================] - 1s 82us/step - loss: 0.0575 - acc: 0.9724 - val_loss: 6.9736 - val_acc: 0.3379\n",
      "Epoch 154/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0713 - acc: 0.9683 - val_loss: 6.6357 - val_acc: 0.3429\n",
      "Epoch 155/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0694 - acc: 0.9695 - val_loss: 6.5448 - val_acc: 0.3387\n",
      "Epoch 156/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0548 - acc: 0.9726 - val_loss: 6.9270 - val_acc: 0.3334\n",
      "Epoch 157/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0665 - acc: 0.9692 - val_loss: 6.7236 - val_acc: 0.3358\n",
      "Epoch 158/400\n",
      "9880/9880 [==============================] - 1s 83us/step - loss: 0.0630 - acc: 0.9715 - val_loss: 6.8607 - val_acc: 0.3350\n",
      "Epoch 159/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0555 - acc: 0.9733 - val_loss: 6.7555 - val_acc: 0.3291\n",
      "Epoch 160/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0556 - acc: 0.9716 - val_loss: 7.0417 - val_acc: 0.3334\n",
      "Epoch 161/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0547 - acc: 0.9718 - val_loss: 6.9780 - val_acc: 0.3415\n",
      "Epoch 162/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0625 - acc: 0.9712 - val_loss: 7.0507 - val_acc: 0.3417\n",
      "Epoch 163/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0582 - acc: 0.9707 - val_loss: 7.1389 - val_acc: 0.3170\n",
      "Epoch 164/400\n",
      "9880/9880 [==============================] - 1s 100us/step - loss: 0.0549 - acc: 0.9702 - val_loss: 7.2559 - val_acc: 0.3316\n",
      "Epoch 165/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0509 - acc: 0.9723 - val_loss: 7.0164 - val_acc: 0.3437\n",
      "Epoch 166/400\n",
      "9880/9880 [==============================] - 1s 89us/step - loss: 0.0609 - acc: 0.9739 - val_loss: 6.9583 - val_acc: 0.3304\n",
      "Epoch 167/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0638 - acc: 0.9723 - val_loss: 7.1770 - val_acc: 0.3326\n",
      "Epoch 168/400\n",
      "9880/9880 [==============================] - 1s 100us/step - loss: 0.0600 - acc: 0.9730 - val_loss: 6.8900 - val_acc: 0.3350\n",
      "Epoch 169/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0692 - acc: 0.9700 - val_loss: 6.6295 - val_acc: 0.3419\n",
      "Epoch 170/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0469 - acc: 0.9747 - val_loss: 7.2273 - val_acc: 0.3362\n",
      "Epoch 171/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.0557 - acc: 0.9727 - val_loss: 7.2807 - val_acc: 0.3549\n",
      "Epoch 172/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0613 - acc: 0.9712 - val_loss: 7.0253 - val_acc: 0.3330\n",
      "Epoch 173/400\n",
      "9880/9880 [==============================] - 1s 88us/step - loss: 0.0545 - acc: 0.9722 - val_loss: 6.7851 - val_acc: 0.3360\n",
      "Epoch 174/400\n",
      "9880/9880 [==============================] - 1s 89us/step - loss: 0.1104 - acc: 0.9620 - val_loss: 6.3891 - val_acc: 0.3373\n",
      "Epoch 175/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0459 - acc: 0.9757 - val_loss: 6.9549 - val_acc: 0.3381\n",
      "Epoch 176/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0553 - acc: 0.9720 - val_loss: 7.1270 - val_acc: 0.3395\n",
      "Epoch 177/400\n",
      "9880/9880 [==============================] - 1s 89us/step - loss: 0.0564 - acc: 0.9716 - val_loss: 7.1937 - val_acc: 0.3346\n",
      "Epoch 178/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0583 - acc: 0.9716 - val_loss: 7.0660 - val_acc: 0.3332\n",
      "Epoch 179/400\n",
      "9880/9880 [==============================] - 1s 87us/step - loss: 0.0517 - acc: 0.9738 - val_loss: 7.0508 - val_acc: 0.3387\n",
      "Epoch 180/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0544 - acc: 0.9727 - val_loss: 7.4443 - val_acc: 0.3366\n",
      "Epoch 181/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0567 - acc: 0.9707 - val_loss: 7.2042 - val_acc: 0.3433\n",
      "Epoch 182/400\n",
      "9880/9880 [==============================] - 1s 87us/step - loss: 0.0934 - acc: 0.9670 - val_loss: 7.1211 - val_acc: 0.3427\n",
      "Epoch 183/400\n",
      "9880/9880 [==============================] - 1s 83us/step - loss: 0.0571 - acc: 0.9718 - val_loss: 7.0556 - val_acc: 0.3340\n",
      "Epoch 184/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0536 - acc: 0.9746 - val_loss: 6.8652 - val_acc: 0.3411\n",
      "Epoch 185/400\n",
      "9880/9880 [==============================] - 1s 83us/step - loss: 0.0541 - acc: 0.9736 - val_loss: 7.3180 - val_acc: 0.3411\n",
      "Epoch 186/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0716 - acc: 0.9696 - val_loss: 6.7208 - val_acc: 0.3373\n",
      "Epoch 187/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0510 - acc: 0.9756 - val_loss: 7.1141 - val_acc: 0.3326\n",
      "Epoch 188/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.0602 - acc: 0.9703 - val_loss: 7.0275 - val_acc: 0.3360\n",
      "Epoch 189/400\n",
      "9880/9880 [==============================] - 1s 88us/step - loss: 0.0526 - acc: 0.9726 - val_loss: 7.5223 - val_acc: 0.3452\n",
      "Epoch 190/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0552 - acc: 0.9724 - val_loss: 7.1574 - val_acc: 0.3350\n",
      "Epoch 191/400\n",
      "9880/9880 [==============================] - 1s 87us/step - loss: 0.0608 - acc: 0.9723 - val_loss: 7.2067 - val_acc: 0.3364\n",
      "Epoch 192/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0557 - acc: 0.9726 - val_loss: 7.2290 - val_acc: 0.3358\n",
      "Epoch 193/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0475 - acc: 0.9731 - val_loss: 7.5073 - val_acc: 0.3433\n",
      "Epoch 194/400\n",
      "9880/9880 [==============================] - 1s 87us/step - loss: 0.0535 - acc: 0.9736 - val_loss: 7.2149 - val_acc: 0.3352\n",
      "Epoch 195/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0684 - acc: 0.9710 - val_loss: 6.8961 - val_acc: 0.3352\n",
      "Epoch 196/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0508 - acc: 0.9749 - val_loss: 7.5472 - val_acc: 0.3275\n",
      "Epoch 197/400\n",
      "9880/9880 [==============================] - 1s 89us/step - loss: 0.0552 - acc: 0.9727 - val_loss: 7.3526 - val_acc: 0.3429\n",
      "Epoch 198/400\n",
      "9880/9880 [==============================] - 1s 103us/step - loss: 0.0578 - acc: 0.9725 - val_loss: 7.4456 - val_acc: 0.3293\n",
      "Epoch 199/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0671 - acc: 0.9722 - val_loss: 7.4751 - val_acc: 0.3391\n",
      "Epoch 200/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.0469 - acc: 0.9731 - val_loss: 7.4971 - val_acc: 0.3275\n",
      "Epoch 201/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0690 - acc: 0.9688 - val_loss: 7.1365 - val_acc: 0.3381\n",
      "Epoch 202/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.0450 - acc: 0.9749 - val_loss: 7.2131 - val_acc: 0.3381\n",
      "Epoch 203/400\n",
      "9880/9880 [==============================] - 1s 89us/step - loss: 0.0546 - acc: 0.9726 - val_loss: 7.3232 - val_acc: 0.3403\n",
      "Epoch 204/400\n",
      "9880/9880 [==============================] - 1s 90us/step - loss: 0.0535 - acc: 0.9730 - val_loss: 7.4445 - val_acc: 0.3308\n",
      "Epoch 205/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.0560 - acc: 0.9728 - val_loss: 7.2247 - val_acc: 0.3283\n",
      "Epoch 206/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0556 - acc: 0.9724 - val_loss: 7.4242 - val_acc: 0.3379\n",
      "Epoch 207/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0529 - acc: 0.9732 - val_loss: 7.0548 - val_acc: 0.3448\n",
      "Epoch 208/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0531 - acc: 0.9738 - val_loss: 7.4905 - val_acc: 0.3069\n",
      "Epoch 209/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0726 - acc: 0.9704 - val_loss: 7.0850 - val_acc: 0.3466\n",
      "Epoch 210/400\n",
      "9880/9880 [==============================] - 1s 101us/step - loss: 0.0461 - acc: 0.9754 - val_loss: 7.2049 - val_acc: 0.3427\n",
      "Epoch 211/400\n",
      "9880/9880 [==============================] - 1s 97us/step - loss: 0.0612 - acc: 0.9722 - val_loss: 7.1120 - val_acc: 0.3338\n",
      "Epoch 212/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.0549 - acc: 0.9740 - val_loss: 7.2588 - val_acc: 0.3350\n",
      "Epoch 213/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0463 - acc: 0.9750 - val_loss: 7.2462 - val_acc: 0.3364\n",
      "Epoch 214/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0620 - acc: 0.9711 - val_loss: 7.1276 - val_acc: 0.3352\n",
      "Epoch 215/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0683 - acc: 0.9697 - val_loss: 6.6962 - val_acc: 0.3385\n",
      "Epoch 216/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0388 - acc: 0.9788 - val_loss: 7.4656 - val_acc: 0.3445\n",
      "Epoch 217/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.0567 - acc: 0.9728 - val_loss: 7.3482 - val_acc: 0.3310\n",
      "Epoch 218/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0497 - acc: 0.9740 - val_loss: 7.2618 - val_acc: 0.3352\n",
      "Epoch 219/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0472 - acc: 0.9747 - val_loss: 7.2533 - val_acc: 0.3366\n",
      "Epoch 220/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0545 - acc: 0.9726 - val_loss: 7.1007 - val_acc: 0.3385\n",
      "Epoch 221/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0563 - acc: 0.9720 - val_loss: 7.0971 - val_acc: 0.3259\n",
      "Epoch 222/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.0549 - acc: 0.9755 - val_loss: 7.3375 - val_acc: 0.3245\n",
      "Epoch 223/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0593 - acc: 0.9730 - val_loss: 6.8944 - val_acc: 0.3358\n",
      "Epoch 224/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0546 - acc: 0.9730 - val_loss: 7.1757 - val_acc: 0.3168\n",
      "Epoch 225/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0471 - acc: 0.9758 - val_loss: 7.0547 - val_acc: 0.3370\n",
      "Epoch 226/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.0595 - acc: 0.9724 - val_loss: 7.0086 - val_acc: 0.3431\n",
      "Epoch 227/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.0435 - acc: 0.9756 - val_loss: 7.1375 - val_acc: 0.3464\n",
      "Epoch 228/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0716 - acc: 0.9715 - val_loss: 6.9662 - val_acc: 0.3470\n",
      "Epoch 229/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0453 - acc: 0.9752 - val_loss: 7.1064 - val_acc: 0.3399\n",
      "Epoch 230/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0526 - acc: 0.9735 - val_loss: 7.4192 - val_acc: 0.3393\n",
      "Epoch 231/400\n",
      "9880/9880 [==============================] - 1s 90us/step - loss: 0.0517 - acc: 0.9725 - val_loss: 7.5190 - val_acc: 0.3338\n",
      "Epoch 232/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0520 - acc: 0.9749 - val_loss: 7.5870 - val_acc: 0.3346\n",
      "Epoch 233/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.0588 - acc: 0.9720 - val_loss: 7.0929 - val_acc: 0.3377\n",
      "Epoch 234/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0474 - acc: 0.9763 - val_loss: 7.3065 - val_acc: 0.3350\n",
      "Epoch 235/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0813 - acc: 0.9693 - val_loss: 6.7974 - val_acc: 0.3381\n",
      "Epoch 236/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.0412 - acc: 0.9767 - val_loss: 7.4023 - val_acc: 0.3391\n",
      "Epoch 237/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9880/9880 [==============================] - 1s 87us/step - loss: 0.0521 - acc: 0.9736 - val_loss: 6.9816 - val_acc: 0.3441\n",
      "Epoch 238/400\n",
      "9880/9880 [==============================] - 1s 87us/step - loss: 0.0472 - acc: 0.9745 - val_loss: 7.1854 - val_acc: 0.3368\n",
      "Epoch 239/400\n",
      "9880/9880 [==============================] - 1s 88us/step - loss: 0.0443 - acc: 0.9738 - val_loss: 7.3880 - val_acc: 0.3419\n",
      "Epoch 240/400\n",
      "9880/9880 [==============================] - 1s 88us/step - loss: 0.0575 - acc: 0.9720 - val_loss: 7.2090 - val_acc: 0.3364\n",
      "Epoch 241/400\n",
      "9880/9880 [==============================] - 1s 88us/step - loss: 0.0599 - acc: 0.9733 - val_loss: 7.4421 - val_acc: 0.3385\n",
      "Epoch 242/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.0479 - acc: 0.9748 - val_loss: 7.7917 - val_acc: 0.3370\n",
      "Epoch 243/400\n",
      "9880/9880 [==============================] - 1s 89us/step - loss: 0.0518 - acc: 0.9728 - val_loss: 7.3882 - val_acc: 0.3433\n",
      "Epoch 244/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0544 - acc: 0.9748 - val_loss: 7.3163 - val_acc: 0.3395\n",
      "Epoch 245/400\n",
      "9880/9880 [==============================] - 1s 99us/step - loss: 0.0469 - acc: 0.9748 - val_loss: 7.3264 - val_acc: 0.3373\n",
      "Epoch 246/400\n",
      "9880/9880 [==============================] - 1s 101us/step - loss: 0.0609 - acc: 0.9718 - val_loss: 7.1755 - val_acc: 0.3445\n",
      "Epoch 247/400\n",
      "9880/9880 [==============================] - 1s 116us/step - loss: 0.0455 - acc: 0.9759 - val_loss: 7.4332 - val_acc: 0.3431\n",
      "Epoch 248/400\n",
      "9880/9880 [==============================] - 1s 120us/step - loss: 0.0695 - acc: 0.9703 - val_loss: 7.2268 - val_acc: 0.3360\n",
      "Epoch 249/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0542 - acc: 0.9736 - val_loss: 7.0536 - val_acc: 0.3395\n",
      "Epoch 250/400\n",
      "9880/9880 [==============================] - 1s 89us/step - loss: 0.0484 - acc: 0.9756 - val_loss: 7.3779 - val_acc: 0.3385\n",
      "Epoch 251/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0483 - acc: 0.9768 - val_loss: 7.0193 - val_acc: 0.3344\n",
      "Epoch 252/400\n",
      "9880/9880 [==============================] - 1s 110us/step - loss: 0.0609 - acc: 0.9729 - val_loss: 6.9429 - val_acc: 0.3383\n",
      "Epoch 253/400\n",
      "9880/9880 [==============================] - 1s 114us/step - loss: 0.0459 - acc: 0.9756 - val_loss: 7.3683 - val_acc: 0.3310\n",
      "Epoch 254/400\n",
      "9880/9880 [==============================] - 1s 109us/step - loss: 0.0618 - acc: 0.9724 - val_loss: 7.0812 - val_acc: 0.3356\n",
      "Epoch 255/400\n",
      "9880/9880 [==============================] - 1s 102us/step - loss: 0.0459 - acc: 0.9747 - val_loss: 7.1548 - val_acc: 0.3362\n",
      "Epoch 256/400\n",
      "9880/9880 [==============================] - 1s 104us/step - loss: 0.0473 - acc: 0.9747 - val_loss: 7.4403 - val_acc: 0.3296\n",
      "Epoch 257/400\n",
      "9880/9880 [==============================] - 1s 101us/step - loss: 0.0517 - acc: 0.9749 - val_loss: 7.6403 - val_acc: 0.3322\n",
      "Epoch 258/400\n",
      "9880/9880 [==============================] - 1s 106us/step - loss: 0.0530 - acc: 0.9726 - val_loss: 7.2968 - val_acc: 0.3358\n",
      "Epoch 259/400\n",
      "9880/9880 [==============================] - 1s 98us/step - loss: 0.0594 - acc: 0.9747 - val_loss: 7.2080 - val_acc: 0.3306\n",
      "Epoch 260/400\n",
      "9880/9880 [==============================] - 1s 101us/step - loss: 0.0423 - acc: 0.9761 - val_loss: 7.6629 - val_acc: 0.3308\n",
      "Epoch 261/400\n",
      "9880/9880 [==============================] - 1s 104us/step - loss: 0.0531 - acc: 0.9745 - val_loss: 7.5346 - val_acc: 0.3302\n",
      "Epoch 262/400\n",
      "9880/9880 [==============================] - 1s 100us/step - loss: 0.0485 - acc: 0.9735 - val_loss: 7.4178 - val_acc: 0.3334\n",
      "Epoch 263/400\n",
      "9880/9880 [==============================] - 1s 101us/step - loss: 0.0599 - acc: 0.9724 - val_loss: 7.4126 - val_acc: 0.3450\n",
      "Epoch 264/400\n",
      "9880/9880 [==============================] - 1s 103us/step - loss: 0.0488 - acc: 0.9755 - val_loss: 7.4880 - val_acc: 0.3358\n",
      "Epoch 265/400\n",
      "9880/9880 [==============================] - 1s 100us/step - loss: 0.0511 - acc: 0.9756 - val_loss: 7.0454 - val_acc: 0.3271\n",
      "Epoch 266/400\n",
      "9880/9880 [==============================] - 1s 99us/step - loss: 0.0479 - acc: 0.9751 - val_loss: 7.2613 - val_acc: 0.3431\n",
      "Epoch 267/400\n",
      "9880/9880 [==============================] - 1s 99us/step - loss: 0.0448 - acc: 0.9752 - val_loss: 7.3095 - val_acc: 0.3385\n",
      "Epoch 268/400\n",
      "9880/9880 [==============================] - 1s 113us/step - loss: 0.0499 - acc: 0.9747 - val_loss: 7.5800 - val_acc: 0.3448\n",
      "Epoch 269/400\n",
      "9880/9880 [==============================] - 1s 105us/step - loss: 0.0490 - acc: 0.9744 - val_loss: 7.3297 - val_acc: 0.3334\n",
      "Epoch 270/400\n",
      "9880/9880 [==============================] - 1s 98us/step - loss: 0.0582 - acc: 0.9727 - val_loss: 7.1427 - val_acc: 0.3346\n",
      "Epoch 271/400\n",
      "9880/9880 [==============================] - 1s 104us/step - loss: 0.0495 - acc: 0.9747 - val_loss: 7.3877 - val_acc: 0.3269\n",
      "Epoch 272/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.0570 - acc: 0.9727 - val_loss: 6.9099 - val_acc: 0.3427\n",
      "Epoch 273/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.0444 - acc: 0.9749 - val_loss: 7.6692 - val_acc: 0.3289\n",
      "Epoch 274/400\n",
      "9880/9880 [==============================] - 1s 88us/step - loss: 0.0561 - acc: 0.9750 - val_loss: 7.3231 - val_acc: 0.3385\n",
      "Epoch 275/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0463 - acc: 0.9758 - val_loss: 7.2467 - val_acc: 0.3334\n",
      "Epoch 276/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0471 - acc: 0.9739 - val_loss: 7.4447 - val_acc: 0.3330\n",
      "Epoch 277/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0482 - acc: 0.9748 - val_loss: 7.4993 - val_acc: 0.3395\n",
      "Epoch 278/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0461 - acc: 0.9742 - val_loss: 7.0256 - val_acc: 0.3289\n",
      "Epoch 279/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.0481 - acc: 0.9760 - val_loss: 7.6725 - val_acc: 0.3308\n",
      "Epoch 280/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.0551 - acc: 0.9736 - val_loss: 7.4447 - val_acc: 0.3385\n",
      "Epoch 281/400\n",
      "9880/9880 [==============================] - 1s 89us/step - loss: 0.0402 - acc: 0.9782 - val_loss: 7.9049 - val_acc: 0.3368\n",
      "Epoch 282/400\n",
      "9880/9880 [==============================] - 1s 87us/step - loss: 0.0564 - acc: 0.9717 - val_loss: 7.4584 - val_acc: 0.3370\n",
      "Epoch 283/400\n",
      "9880/9880 [==============================] - 1s 88us/step - loss: 0.0461 - acc: 0.9766 - val_loss: 7.6639 - val_acc: 0.3358\n",
      "Epoch 284/400\n",
      "9880/9880 [==============================] - 1s 91us/step - loss: 0.0506 - acc: 0.9750 - val_loss: 7.4096 - val_acc: 0.3413\n",
      "Epoch 285/400\n",
      "9880/9880 [==============================] - 1s 87us/step - loss: 0.0471 - acc: 0.9760 - val_loss: 7.4459 - val_acc: 0.3399\n",
      "Epoch 286/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0570 - acc: 0.9719 - val_loss: 7.3885 - val_acc: 0.3356\n",
      "Epoch 287/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0466 - acc: 0.9750 - val_loss: 7.4747 - val_acc: 0.3334\n",
      "Epoch 288/400\n",
      "9880/9880 [==============================] - 1s 83us/step - loss: 0.0483 - acc: 0.9757 - val_loss: 7.4975 - val_acc: 0.3328\n",
      "Epoch 289/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0536 - acc: 0.9747 - val_loss: 7.4191 - val_acc: 0.3322\n",
      "Epoch 290/400\n",
      "9880/9880 [==============================] - 1s 87us/step - loss: 0.0551 - acc: 0.9751 - val_loss: 7.6129 - val_acc: 0.3348\n",
      "Epoch 291/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0668 - acc: 0.9727 - val_loss: 6.6978 - val_acc: 0.3352\n",
      "Epoch 292/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0393 - acc: 0.9777 - val_loss: 7.6820 - val_acc: 0.3289\n",
      "Epoch 293/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0530 - acc: 0.9749 - val_loss: 7.3371 - val_acc: 0.3320\n",
      "Epoch 294/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0599 - acc: 0.9748 - val_loss: 7.4212 - val_acc: 0.3368\n",
      "Epoch 295/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0558 - acc: 0.9734 - val_loss: 7.0858 - val_acc: 0.3409\n",
      "Epoch 296/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9880/9880 [==============================] - 1s 87us/step - loss: 0.0566 - acc: 0.9731 - val_loss: 7.0158 - val_acc: 0.3277\n",
      "Epoch 297/400\n",
      "9880/9880 [==============================] - 1s 87us/step - loss: 0.0437 - acc: 0.9766 - val_loss: 7.3330 - val_acc: 0.3368\n",
      "Epoch 298/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0746 - acc: 0.9702 - val_loss: 6.9681 - val_acc: 0.3346\n",
      "Epoch 299/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0582 - acc: 0.9742 - val_loss: 6.7658 - val_acc: 0.3281\n",
      "Epoch 300/400\n",
      "9880/9880 [==============================] - 1s 83us/step - loss: 0.0494 - acc: 0.9749 - val_loss: 7.4086 - val_acc: 0.3484\n",
      "Epoch 301/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0428 - acc: 0.9761 - val_loss: 7.4774 - val_acc: 0.3328\n",
      "Epoch 302/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0534 - acc: 0.9736 - val_loss: 7.1496 - val_acc: 0.3281\n",
      "Epoch 303/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0479 - acc: 0.9752 - val_loss: 7.4313 - val_acc: 0.3352\n",
      "Epoch 304/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0576 - acc: 0.9734 - val_loss: 7.0727 - val_acc: 0.3308\n",
      "Epoch 305/400\n",
      "9880/9880 [==============================] - 1s 88us/step - loss: 0.0532 - acc: 0.9745 - val_loss: 7.3563 - val_acc: 0.3271\n",
      "Epoch 306/400\n",
      "9880/9880 [==============================] - 1s 90us/step - loss: 0.0568 - acc: 0.9731 - val_loss: 6.6032 - val_acc: 0.3342\n",
      "Epoch 307/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0487 - acc: 0.9749 - val_loss: 7.4155 - val_acc: 0.3431\n",
      "Epoch 308/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0472 - acc: 0.9757 - val_loss: 7.0419 - val_acc: 0.3326\n",
      "Epoch 309/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0447 - acc: 0.9763 - val_loss: 7.6491 - val_acc: 0.3399\n",
      "Epoch 310/400\n",
      "9880/9880 [==============================] - 1s 82us/step - loss: 0.0573 - acc: 0.9742 - val_loss: 7.5304 - val_acc: 0.3312\n",
      "Epoch 311/400\n",
      "9880/9880 [==============================] - 1s 83us/step - loss: 0.0418 - acc: 0.9759 - val_loss: 7.5334 - val_acc: 0.3223\n",
      "Epoch 312/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0546 - acc: 0.9744 - val_loss: 7.2732 - val_acc: 0.3466\n",
      "Epoch 313/400\n",
      "9880/9880 [==============================] - 1s 87us/step - loss: 0.0494 - acc: 0.9754 - val_loss: 7.5372 - val_acc: 0.3413\n",
      "Epoch 314/400\n",
      "9880/9880 [==============================] - 1s 83us/step - loss: 0.0484 - acc: 0.9752 - val_loss: 7.5110 - val_acc: 0.3338\n",
      "Epoch 315/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0495 - acc: 0.9748 - val_loss: 7.3573 - val_acc: 0.3332\n",
      "Epoch 316/400\n",
      "9880/9880 [==============================] - 1s 83us/step - loss: 0.0526 - acc: 0.9745 - val_loss: 7.6444 - val_acc: 0.3340\n",
      "Epoch 317/400\n",
      "9880/9880 [==============================] - 1s 83us/step - loss: 0.0551 - acc: 0.9745 - val_loss: 7.2703 - val_acc: 0.3393\n",
      "Epoch 318/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0528 - acc: 0.9732 - val_loss: 7.2567 - val_acc: 0.3338\n",
      "Epoch 319/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0455 - acc: 0.9763 - val_loss: 7.1944 - val_acc: 0.3381\n",
      "Epoch 320/400\n",
      "9880/9880 [==============================] - 1s 83us/step - loss: 0.0584 - acc: 0.9737 - val_loss: 7.2202 - val_acc: 0.3233\n",
      "Epoch 321/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0421 - acc: 0.9768 - val_loss: 7.4337 - val_acc: 0.3387\n",
      "Epoch 322/400\n",
      "9880/9880 [==============================] - 1s 83us/step - loss: 0.0548 - acc: 0.9743 - val_loss: 7.3152 - val_acc: 0.3314\n",
      "Epoch 323/400\n",
      "9880/9880 [==============================] - 1s 83us/step - loss: 0.0511 - acc: 0.9759 - val_loss: 7.5022 - val_acc: 0.3287\n",
      "Epoch 324/400\n",
      "9880/9880 [==============================] - 1s 83us/step - loss: 0.0492 - acc: 0.9769 - val_loss: 8.0741 - val_acc: 0.3186\n",
      "Epoch 325/400\n",
      "9880/9880 [==============================] - 1s 83us/step - loss: 0.0504 - acc: 0.9753 - val_loss: 7.2782 - val_acc: 0.3293\n",
      "Epoch 326/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0469 - acc: 0.9743 - val_loss: 7.5366 - val_acc: 0.3204\n",
      "Epoch 327/400\n",
      "9880/9880 [==============================] - 1s 83us/step - loss: 0.0616 - acc: 0.9738 - val_loss: 7.3052 - val_acc: 0.3300\n",
      "Epoch 328/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0424 - acc: 0.9772 - val_loss: 7.3876 - val_acc: 0.3344\n",
      "Epoch 329/400\n",
      "9880/9880 [==============================] - 1s 87us/step - loss: 0.0533 - acc: 0.9729 - val_loss: 7.0196 - val_acc: 0.3326\n",
      "Epoch 330/400\n",
      "9880/9880 [==============================] - 1s 84us/step - loss: 0.0499 - acc: 0.9746 - val_loss: 7.1876 - val_acc: 0.3395\n",
      "Epoch 331/400\n",
      "9880/9880 [==============================] - 1s 87us/step - loss: 0.0400 - acc: 0.9772 - val_loss: 7.6873 - val_acc: 0.3364\n",
      "Epoch 332/400\n",
      "9880/9880 [==============================] - 1s 89us/step - loss: 0.0535 - acc: 0.9744 - val_loss: 7.4683 - val_acc: 0.3291\n",
      "Epoch 333/400\n",
      "9880/9880 [==============================] - 1s 102us/step - loss: 0.0546 - acc: 0.9739 - val_loss: 7.1399 - val_acc: 0.3285\n",
      "Epoch 334/400\n",
      "9880/9880 [==============================] - 1s 88us/step - loss: 0.0424 - acc: 0.9757 - val_loss: 7.3230 - val_acc: 0.3310\n",
      "Epoch 335/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0652 - acc: 0.9714 - val_loss: 7.4076 - val_acc: 0.3377\n",
      "Epoch 336/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0486 - acc: 0.9758 - val_loss: 7.6413 - val_acc: 0.3218\n",
      "Epoch 337/400\n",
      "9880/9880 [==============================] - 1s 89us/step - loss: 0.0473 - acc: 0.9757 - val_loss: 7.6045 - val_acc: 0.3310\n",
      "Epoch 338/400\n",
      "9880/9880 [==============================] - 1s 86us/step - loss: 0.0459 - acc: 0.9771 - val_loss: 7.3827 - val_acc: 0.3212\n",
      "Epoch 339/400\n",
      "9880/9880 [==============================] - 1s 85us/step - loss: 0.0496 - acc: 0.9760 - val_loss: 7.3797 - val_acc: 0.3251\n",
      "Epoch 340/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0534 - acc: 0.9745 - val_loss: 7.5601 - val_acc: 0.3318\n",
      "Epoch 341/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0506 - acc: 0.9752 - val_loss: 7.1939 - val_acc: 0.3285\n",
      "Epoch 342/400\n",
      "9880/9880 [==============================] - 1s 115us/step - loss: 0.0448 - acc: 0.9757 - val_loss: 7.4312 - val_acc: 0.3291\n",
      "Epoch 343/400\n",
      "9880/9880 [==============================] - 1s 111us/step - loss: 0.0522 - acc: 0.9754 - val_loss: 7.2255 - val_acc: 0.3324\n",
      "Epoch 344/400\n",
      "9880/9880 [==============================] - 1s 116us/step - loss: 0.0496 - acc: 0.9745 - val_loss: 7.4568 - val_acc: 0.3332\n",
      "Epoch 345/400\n",
      "9880/9880 [==============================] - 1s 112us/step - loss: 0.0448 - acc: 0.9756 - val_loss: 7.2110 - val_acc: 0.3405\n",
      "Epoch 346/400\n",
      "9880/9880 [==============================] - 1s 99us/step - loss: 0.0711 - acc: 0.9704 - val_loss: 6.9030 - val_acc: 0.3362\n",
      "Epoch 347/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0391 - acc: 0.9766 - val_loss: 8.0629 - val_acc: 0.3279\n",
      "Epoch 348/400\n",
      "9880/9880 [==============================] - 1s 106us/step - loss: 0.0541 - acc: 0.9730 - val_loss: 7.7604 - val_acc: 0.3314\n",
      "Epoch 349/400\n",
      "9880/9880 [==============================] - 1s 105us/step - loss: 0.0552 - acc: 0.9749 - val_loss: 6.8669 - val_acc: 0.3265\n",
      "Epoch 350/400\n",
      "9880/9880 [==============================] - 1s 104us/step - loss: 0.0581 - acc: 0.9732 - val_loss: 7.2866 - val_acc: 0.3269\n",
      "Epoch 351/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.0429 - acc: 0.9771 - val_loss: 7.1698 - val_acc: 0.3393\n",
      "Epoch 352/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0431 - acc: 0.9769 - val_loss: 7.7831 - val_acc: 0.3265\n",
      "Epoch 353/400\n",
      "9880/9880 [==============================] - 1s 98us/step - loss: 0.0614 - acc: 0.9721 - val_loss: 7.5438 - val_acc: 0.3322\n",
      "Epoch 354/400\n",
      "9880/9880 [==============================] - 1s 97us/step - loss: 0.0465 - acc: 0.9774 - val_loss: 7.5324 - val_acc: 0.3377\n",
      "Epoch 355/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9880/9880 [==============================] - 1s 99us/step - loss: 0.0447 - acc: 0.9763 - val_loss: 7.8375 - val_acc: 0.3330\n",
      "Epoch 356/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0539 - acc: 0.9741 - val_loss: 7.4520 - val_acc: 0.3381\n",
      "Epoch 357/400\n",
      "9880/9880 [==============================] - 1s 98us/step - loss: 0.0456 - acc: 0.9758 - val_loss: 7.6110 - val_acc: 0.3366\n",
      "Epoch 358/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0573 - acc: 0.9739 - val_loss: 7.4950 - val_acc: 0.3275\n",
      "Epoch 359/400\n",
      "9880/9880 [==============================] - 1s 90us/step - loss: 0.0457 - acc: 0.9760 - val_loss: 7.7317 - val_acc: 0.3401\n",
      "Epoch 360/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.0764 - acc: 0.9716 - val_loss: 7.1488 - val_acc: 0.3346\n",
      "Epoch 361/400\n",
      "9880/9880 [==============================] - 1s 97us/step - loss: 0.0378 - acc: 0.9783 - val_loss: 7.6437 - val_acc: 0.3360\n",
      "Epoch 362/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0478 - acc: 0.9759 - val_loss: 7.7114 - val_acc: 0.3263\n",
      "Epoch 363/400\n",
      "9880/9880 [==============================] - 1s 98us/step - loss: 0.0744 - acc: 0.9725 - val_loss: 7.2984 - val_acc: 0.3273\n",
      "Epoch 364/400\n",
      "9880/9880 [==============================] - 1s 97us/step - loss: 0.0415 - acc: 0.9774 - val_loss: 7.2954 - val_acc: 0.3356\n",
      "Epoch 365/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0520 - acc: 0.9760 - val_loss: 8.1530 - val_acc: 0.3231\n",
      "Epoch 366/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0538 - acc: 0.9738 - val_loss: 7.6874 - val_acc: 0.3304\n",
      "Epoch 367/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0465 - acc: 0.9762 - val_loss: 7.5128 - val_acc: 0.3354\n",
      "Epoch 368/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0486 - acc: 0.9744 - val_loss: 7.7482 - val_acc: 0.3334\n",
      "Epoch 369/400\n",
      "9880/9880 [==============================] - 1s 92us/step - loss: 0.0513 - acc: 0.9749 - val_loss: 7.9655 - val_acc: 0.3277\n",
      "Epoch 370/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0484 - acc: 0.9749 - val_loss: 7.4070 - val_acc: 0.3373\n",
      "Epoch 371/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.0436 - acc: 0.9768 - val_loss: 8.0657 - val_acc: 0.3326\n",
      "Epoch 372/400\n",
      "9880/9880 [==============================] - 1s 104us/step - loss: 0.0576 - acc: 0.9725 - val_loss: 7.7640 - val_acc: 0.3375\n",
      "Epoch 373/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0450 - acc: 0.9765 - val_loss: 7.5236 - val_acc: 0.3393\n",
      "Epoch 374/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0460 - acc: 0.9764 - val_loss: 7.9791 - val_acc: 0.3346\n",
      "Epoch 375/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0522 - acc: 0.9736 - val_loss: 7.2781 - val_acc: 0.3340\n",
      "Epoch 376/400\n",
      "9880/9880 [==============================] - 1s 97us/step - loss: 0.0436 - acc: 0.9764 - val_loss: 7.8720 - val_acc: 0.3218\n",
      "Epoch 377/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0417 - acc: 0.9761 - val_loss: 7.8032 - val_acc: 0.3273\n",
      "Epoch 378/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0473 - acc: 0.9765 - val_loss: 7.3205 - val_acc: 0.3306\n",
      "Epoch 379/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0478 - acc: 0.9760 - val_loss: 7.5322 - val_acc: 0.3336\n",
      "Epoch 380/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0441 - acc: 0.9763 - val_loss: 7.8829 - val_acc: 0.3405\n",
      "Epoch 381/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0553 - acc: 0.9746 - val_loss: 7.6318 - val_acc: 0.3356\n",
      "Epoch 382/400\n",
      "9880/9880 [==============================] - 1s 100us/step - loss: 0.0493 - acc: 0.9751 - val_loss: 7.6517 - val_acc: 0.3261\n",
      "Epoch 383/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0474 - acc: 0.9775 - val_loss: 7.7666 - val_acc: 0.3304\n",
      "Epoch 384/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0575 - acc: 0.9728 - val_loss: 7.6083 - val_acc: 0.3324\n",
      "Epoch 385/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0470 - acc: 0.9763 - val_loss: 7.7560 - val_acc: 0.3340\n",
      "Epoch 386/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0499 - acc: 0.9749 - val_loss: 7.4322 - val_acc: 0.3383\n",
      "Epoch 387/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0575 - acc: 0.9739 - val_loss: 7.5052 - val_acc: 0.3324\n",
      "Epoch 388/400\n",
      "9880/9880 [==============================] - 1s 104us/step - loss: 0.0501 - acc: 0.9763 - val_loss: 7.4435 - val_acc: 0.3409\n",
      "Epoch 389/400\n",
      "9880/9880 [==============================] - 1s 107us/step - loss: 0.0510 - acc: 0.9748 - val_loss: 7.3144 - val_acc: 0.3334\n",
      "Epoch 390/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0484 - acc: 0.9754 - val_loss: 7.7997 - val_acc: 0.3285\n",
      "Epoch 391/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.0468 - acc: 0.9759 - val_loss: 7.2169 - val_acc: 0.3298\n",
      "Epoch 392/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0522 - acc: 0.9758 - val_loss: 6.8729 - val_acc: 0.3322\n",
      "Epoch 393/400\n",
      "9880/9880 [==============================] - 1s 95us/step - loss: 0.0425 - acc: 0.9769 - val_loss: 7.7154 - val_acc: 0.3326\n",
      "Epoch 394/400\n",
      "9880/9880 [==============================] - 1s 93us/step - loss: 0.0534 - acc: 0.9756 - val_loss: 7.5364 - val_acc: 0.3273\n",
      "Epoch 395/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0441 - acc: 0.9759 - val_loss: 7.6990 - val_acc: 0.3251\n",
      "Epoch 396/400\n",
      "9880/9880 [==============================] - 1s 96us/step - loss: 0.0594 - acc: 0.9744 - val_loss: 7.1922 - val_acc: 0.3403\n",
      "Epoch 397/400\n",
      "9880/9880 [==============================] - 1s 94us/step - loss: 0.0390 - acc: 0.9772 - val_loss: 7.7212 - val_acc: 0.3364\n",
      "Epoch 398/400\n",
      "9880/9880 [==============================] - 1s 100us/step - loss: 0.0544 - acc: 0.9741 - val_loss: 7.3201 - val_acc: 0.3387\n",
      "Epoch 399/400\n",
      "9880/9880 [==============================] - 1s 103us/step - loss: 0.0406 - acc: 0.9770 - val_loss: 7.5681 - val_acc: 0.3492\n",
      "Epoch 400/400\n",
      "9880/9880 [==============================] - 1s 98us/step - loss: 0.0466 - acc: 0.9753 - val_loss: 7.6141 - val_acc: 0.3318\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=400,\n",
    "                    verbose=1,\n",
    "                    validation_split = 0.333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14814, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(pred, columns=[\"Zero\", \"One\", \"Two\", \"Three\", \"Four\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero</th>\n",
       "      <th>One</th>\n",
       "      <th>Two</th>\n",
       "      <th>Three</th>\n",
       "      <th>Four</th>\n",
       "      <th>AdoptionRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Zero  One  Two  Three  Four  AdoptionRate\n",
       "0     0    0    1      0     0             2\n",
       "1     1    0    0      0     0             0\n",
       "2     0    0    0      1     0             3\n",
       "3     0    0    1      0     0             2\n",
       "4     0    0    1      0     0             2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[\"AdoptionRate\"] = 7\n",
    "pred.loc[pred[\"Zero\"] == 1, \"AdoptionRate\"] = 0\n",
    "pred.loc[pred[\"One\"] == 1, \"AdoptionRate\"] = 1\n",
    "pred.loc[pred[\"Two\"] == 1, \"AdoptionRate\"] = 2\n",
    "pred.loc[pred[\"Three\"] == 1, \"AdoptionRate\"] = 3\n",
    "pred.loc[pred[\"Four\"] == 1, \"AdoptionRate\"] = 4\n",
    "\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = pd.read_csv(\"input/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3948, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>378fcc4fc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73c10e136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72000c4c5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e147a4b9f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43fbba852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77a490ec9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28c4b1b13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>d1eada628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>d134dec34</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bcd464bb8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4e21958c3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7b070aed6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ff8d0708f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>f1e6c9bf3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>248914c05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>948002885</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>111e67cd2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4f4b2ede1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>d77fca061</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ac9fb74b9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>47ef39e7a</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>c69ee9807</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>62dcf8ecb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4df1d19d6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>e8ef8455e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cbd23bc17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4d1a91ccf</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>004ee5cf7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>95fad0a75</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>64341b5db</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>4586798a6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919</th>\n",
       "      <td>e5ec7709d</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>fa0b958ae</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>85fda19ab</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>d6a2fa83e</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>08f25f7da</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>a159e317f</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>09582e51b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926</th>\n",
       "      <td>0c9cc3c3d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3927</th>\n",
       "      <td>fd6a10dd8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3928</th>\n",
       "      <td>3b22e5249</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>62abaa505</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3930</th>\n",
       "      <td>d274a7103</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>4f244a307</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>34e4c214d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3933</th>\n",
       "      <td>67b8ae43b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934</th>\n",
       "      <td>285a40127</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>ce637df13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936</th>\n",
       "      <td>e07d8debe</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3937</th>\n",
       "      <td>5c23692a4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>4dc690fca</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3939</th>\n",
       "      <td>40739eff7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940</th>\n",
       "      <td>e90b93c02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941</th>\n",
       "      <td>0a4831022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>d24a644d5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>6bde0667b</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>e25b59349</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>10bc6fc6a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>2d7a91c59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>e5bbe3e54</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3948 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PetID  AdoptionSpeed\n",
       "0     378fcc4fc              2\n",
       "1     73c10e136              0\n",
       "2     72000c4c5              3\n",
       "3     e147a4b9f              2\n",
       "4     43fbba852              2\n",
       "5     77a490ec9              2\n",
       "6     28c4b1b13              1\n",
       "7     d1eada628              1\n",
       "8     d134dec34              4\n",
       "9     bcd464bb8              1\n",
       "10    4e21958c3              1\n",
       "11    7b070aed6              2\n",
       "12    ff8d0708f              1\n",
       "13    f1e6c9bf3              2\n",
       "14    248914c05              4\n",
       "15    948002885              3\n",
       "16    111e67cd2              4\n",
       "17    4f4b2ede1              2\n",
       "18    d77fca061              4\n",
       "19    ac9fb74b9              2\n",
       "20    47ef39e7a              4\n",
       "21    c69ee9807              4\n",
       "22    62dcf8ecb              1\n",
       "23    4df1d19d6              2\n",
       "24    e8ef8455e              1\n",
       "25    cbd23bc17              2\n",
       "26    4d1a91ccf              3\n",
       "27    004ee5cf7              2\n",
       "28    95fad0a75              3\n",
       "29    64341b5db              1\n",
       "...         ...            ...\n",
       "3918  4586798a6              4\n",
       "3919  e5ec7709d              2\n",
       "3920  fa0b958ae              0\n",
       "3921  85fda19ab              4\n",
       "3922  d6a2fa83e              2\n",
       "3923  08f25f7da              2\n",
       "3924  a159e317f              4\n",
       "3925  09582e51b              2\n",
       "3926  0c9cc3c3d              4\n",
       "3927  fd6a10dd8              4\n",
       "3928  3b22e5249              3\n",
       "3929  62abaa505              2\n",
       "3930  d274a7103              4\n",
       "3931  4f244a307              3\n",
       "3932  34e4c214d              4\n",
       "3933  67b8ae43b              2\n",
       "3934  285a40127              2\n",
       "3935  ce637df13              3\n",
       "3936  e07d8debe              3\n",
       "3937  5c23692a4              2\n",
       "3938  4dc690fca              2\n",
       "3939  40739eff7              4\n",
       "3940  e90b93c02              2\n",
       "3941  0a4831022              4\n",
       "3942  d24a644d5              3\n",
       "3943  6bde0667b              4\n",
       "3944  e25b59349              4\n",
       "3945  10bc6fc6a              1\n",
       "3946  2d7a91c59              4\n",
       "3947  e5bbe3e54              2\n",
       "\n",
       "[3948 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_data[\"AdoptionSpeed\"] = pred[\"AdoptionRate\"].astype(\"int32\")\n",
    "submission_data[\"AdoptionSpeed\"] = submission_data[\"AdoptionSpeed\"].fillna(0)\n",
    "submission_data[\"AdoptionSpeed\"] = submission_data[\"AdoptionSpeed\"].astype(\"int32\")\n",
    "submission_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
